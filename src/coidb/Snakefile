from snakemake.utils import validate

# this container defines the underlying OS for each job when using the workflow
# with --use-conda --use-singularity
singularity: "docker://continuumio/miniconda3:4.9.2"

# Validate config
validate(config, "config.schema.yaml")

nrows = None
if config["testing"]["nrows"] > 0:
    nrows = config["testing"]["nrows"]

localrules: coidb, download, filter, clean, format

wildcard_constraints:
    textfile = "occurrences.txt|dna.txt|Taxon.tsv",
    zipfile = "bold.zip|backbone.zip"

textfile_dict = {'Taxon.tsv': 'backbone.zip',
                 'occurrences.txt': 'bold.zip',
                 'dna.txt': 'bold.zip'}

rule coidb:
    input: expand("bold_clustered.{w}.fasta", w=["assignTaxonomy", "addSpecies"])

rule download_zipfile:
    """
    Download zipfile with database sequences + info
    """
    output:
        "{zipfile}"
    log:
        "logs/download.{zipfile}.log"
    params:
        url = lambda wildcards: config["database"][wildcards.zipfile]
    shell:
        """
        curl -L -o $TMPDIR/{wildcards.zipfile} {params.url} > {log} 2>&1
        mv $TMPDIR/{wildcards.zipfile} {output[0]}
        """

rule download:
    input:
        textfile_dict.values()

rule extract_zipfile:
    input:
        lambda wildcards: textfile_dict[wildcards.textfile]
    output:
        "{textfile}"
    log:
        "logs/extract.{textfile}.log"
    shell:
        """
        f=$(unzip -l {input[0]} | grep -w {output[0]} | rev | cut -f1 -d ' ' | rev)
        unzip -o -d $TMPDIR/ {input[0]} $f >> {log} 2>&1
        mv $TMPDIR/$f {output[0]}
        """


rule extract:
    input:
        textfile_dict.keys()

rule filter:
    """
    Filter the BOLD data to genes and taxa of interest
    
    This also keeps only records with BOLD: ids
    """
    input:
        "occurrences.txt",
        "dna.txt",
        "Taxon.tsv"
    output:
        info = "bold_info_filtered.tsv",
        fasta = "bold_filtered.fasta",
    params:
        genes = config["database"]["gene"],
        filter_taxa = config["database"]["taxa"],
        filter_rank = config["database"]["rank"],
        ranks = config["database"]["ranks"],
        tmpf = "$TMPDIR/bold_filtered.fasta",
        nrows = nrows
    script:
        "scripts/common.py"

rule cluster:
    """
    Cluster the filtered fasta file using vsearch
    """
    input:
        fasta = "bold_filtered.fasta"
    output:
        fasta = "bold_clustered.fasta"
    log:
        "logs/bold/cluster.log"
    conda:
        "envs/cluster.yml"
    threads: 10
    resources:
        runtime = lambda wildcards, attempt: attempt ** 2 * 60 * 10
    params:
        pid = config["database"]["pid"]
    shell:
        """
        cluster_bold.py --threads {threads} --pid {params.pid} \
            {input.fasta} {output.fasta} > {log} 2>&1 
        """

rule clean:
    """
    Cleans headers of sequences in clustered fasta file
    """
    input:
        fasta = "bold_clustered.fasta"
    output:
        fasta = "bold_clustered_cleaned.fasta"
    script:
        "scripts/common.py"


rule format:
    """
    Formats the clustered fasta file into DADA2-ready files
    """
    input:
        fasta = "bold_clustered_cleaned.fasta",
        info = "bold_info_filtered.tsv"
    output:
        assignTaxaFasta = "bold_clustered.assignTaxonomy.fasta",
        addSpeciesFasta = "bold_clustered.addSpecies.fasta"
    script:
        "scripts/common.py"